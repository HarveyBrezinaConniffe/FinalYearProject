{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97319eb7-a338-4150-b4c8-4d18f55bbfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pysmiles\n",
    "import json\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe44faf-504d-4c4f-8490-d123cf33bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfa719-ad06-40c5-ae64-b29777517f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('pysmiles').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219528bc-3d39-4de3-92b8-68ca3d40f490",
   "metadata": {},
   "source": [
    "Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1f31c-304c-47f7-b096-7c177e3a4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data_train = pq.read_table(\"../data/de_train.parquet\").to_pandas()\n",
    "de_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bb3f1-bfac-4900-97d0-720eeeb1d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data_train[\"cell_type\"].unique()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d41ff-e88a-4dcf-8bc1-8dbeb442399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellNameToInt = {de_data_train[\"cell_type\"].unique()[i]: i for i in range(len(de_data_train[\"cell_type\"].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60105c-e6ea-4a93-a489-c50ae2ec588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data_train[\"cell_type_int\"] = de_data_train[\"cell_type\"].map(cellNameToInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecd951-dbee-43dd-9536-856da94eda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellNameToInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97554420-226b-473e-8bba-2eccb71d392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = de_data_train.columns[5:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbab7bc-89ca-45cf-9599-f15c4f8fa1d7",
   "metadata": {},
   "source": [
    "## Divide into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6a660-734b-4e98-818d-597754e68388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell types where all (cell_type, sm) pairs will be used for training\n",
    "train_only_cell_types     = [\"T cells CD4+\", \"T cells CD8+\", \"T regulatory cells\"]\n",
    "# Cell types where only some (cell_type, sm) pairs will be used for training\n",
    "train_and_test_cell_types = [\"B cells\", \"Myeloid cells\", \"NK cells\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bbcd9-9c55-4b6e-86e6-1ee48844f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict mapping cell_name -> list of sm given for cell_name\n",
    "sm_names_by_cell_type = de_data_train.groupby(\"cell_type\")[\"sm_name\"].unique().to_dict()\n",
    "# Get list of small molecules given for cell types with a reduced set of (cell_type, sm) pairs\n",
    "train_and_test_sm = sm_names_by_cell_type[\"B cells\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08441202-3f57-42ec-a9a7-5c450c81b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cell types where only some (cell_type, sm) pairs will be used for training\n",
    "# Choose which small molecules will be used for training and which for test\n",
    "num_b_sm       = len(sm_names_by_cell_type[\"B cells\"])\n",
    "num_myeloid_sm = len(sm_names_by_cell_type[\"Myeloid cells\"])\n",
    "num_nk_sm      = len(sm_names_by_cell_type[\"NK cells\"])\n",
    "\n",
    "b_cell_train       = sm_names_by_cell_type[\"B cells\"][:num_b_sm//2]\n",
    "myeloid_cell_train = sm_names_by_cell_type[\"Myeloid cells\"][:num_myeloid_sm//2]\n",
    "nk_cell_train      = sm_names_by_cell_type[\"NK cells\"][:num_nk_sm//2]\n",
    "\n",
    "b_cell_test       = sm_names_by_cell_type[\"B cells\"][num_b_sm//2:]\n",
    "myeloid_cell_test = sm_names_by_cell_type[\"Myeloid cells\"][num_myeloid_sm//2:]\n",
    "nk_cell_test      = sm_names_by_cell_type[\"NK cells\"][num_nk_sm//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759d99a-ba32-4b89-ad4a-0f92f7a25631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training combinations with all (cell_type, sm) pairs for train only cell types\n",
    "training_combinations = dict((cell_type, sm_names_by_cell_type[cell_type]) for cell_type in train_only_cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe1b45-09b6-41ce-b3e2-f46ec6948e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include training (cell_type, sm) pairs from train_test cell types\n",
    "training_combinations[\"B cells\"] = b_cell_train\n",
    "training_combinations[\"Myeloid cells\"] = myeloid_cell_train\n",
    "training_combinations[\"NK cells\"] = nk_cell_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb13e18-f813-4afe-a5de-c23152f0d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing combinations\n",
    "testing_combinations = {}\n",
    "testing_combinations[\"B cells\"] = b_cell_test\n",
    "testing_combinations[\"Myeloid cells\"] = myeloid_cell_test\n",
    "testing_combinations[\"NK cells\"] = nk_cell_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6ec27-fef4-4af3-a15b-78c12cb1a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e09ef7-6bec-4d72-9b4d-c30ac3613168",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdd432-8bb4-4725-948b-8502bc81b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into (cell_type, sm) pairs\n",
    "training_pairs = set({})\n",
    "for cell_type in training_combinations.keys():\n",
    "    for sm in training_combinations[cell_type]:\n",
    "            for gene_name in gene_names:\n",
    "                training_pairs.add((cell_type+\", \"+sm, gene_name))\n",
    "\n",
    "testing_pairs = set({})\n",
    "for cell_type in testing_combinations.keys():\n",
    "    for sm in testing_combinations[cell_type]:\n",
    "            for gene_name in gene_names:\n",
    "                testing_pairs.add((cell_type+\", \"+sm, gene_name))\n",
    "\n",
    "list(training_pairs)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1980e63-6bdd-4412-a70a-1732e3d5055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data_train[\"cell_type_sm_pair\"] = de_data_train[\"cell_type\"]+\", \"+de_data_train[\"sm_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ffdcc-7895-477b-aa39-fc329f030049",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data_train[de_data_train[\"cell_type_sm_pair\"] == \"T regulatory cells, FK 866\"].iloc[0][5:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5f3ed-ad8f-495b-b3fb-4d0b7f33e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_file = \"../data/sequences_int.jsonl\"\n",
    "\n",
    "gene_symbol_to_id = {}\n",
    "gene_sequences = []\n",
    "\n",
    "with open(sequences_file, \"r\") as sequences:\n",
    "    i = 0\n",
    "    for line in sequences:\n",
    "        json_line = json.loads(line)\n",
    "        gene_sequences.append(json_line[\"seq\"])\n",
    "        gene_symbol_to_id[json_line[\"gene\"]] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93262357-58e8-4215-8232-de8a618be90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sequences = tf.convert_to_tensor(gene_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30e952-6898-4f8b-8ca5-31b3d8e8bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_molecules = de_data_train[\"sm_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80650b79-2613-4678-b131-4bd493dfd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "((32*100000)/8)/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57daedd-f1a8-4d84-8818-c3ba39f0f44b",
   "metadata": {},
   "source": [
    "# Create Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97edb57-a82d-495f-9fe4-c3a29a6851a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GraphLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231179b1-da0e-46ef-9634-7516c918a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NODES = 150\n",
    "MAX_EDGES = 200\n",
    "EMBEDDING_DIM = 120\n",
    "\n",
    "MAX_DNA_LEN = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6807d77-b464-46f8-a7f7-6885e5ea063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_graph(smiles_molecule):\n",
    "    graph = pysmiles.read_smiles(smiles_molecule, explicit_hydrogen=True)\n",
    "    return GraphLayers.convertFromNetworkX(graph, \n",
    "                               MAX_NODES,\n",
    "                               MAX_EDGES, \n",
    "                               EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f75b6-2a62-451a-9f14-4c506d72681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_to_id = {}\n",
    "mol_vertices = []\n",
    "mol_edges = []\n",
    "mol_unis = []\n",
    "mol_adjs = []\n",
    "mol_conns = []\n",
    "mol_edge_adjs = []\n",
    "\n",
    "i = 0\n",
    "for mol in all_molecules:\n",
    "    smiles = de_data_train[de_data_train[\"sm_name\"] == mol].iloc[0][\"SMILES\"]\n",
    "    mol_to_id[mol] = i\n",
    "    mol_ver, mol_edj, mol_uni, mol_am, mol_conn, mol_edgeAdj = smiles_to_graph(smiles)\n",
    "\n",
    "    mol_vertices.append(mol_ver)\n",
    "    mol_edges.append(mol_edj)\n",
    "    mol_unis.append(mol_uni)\n",
    "    mol_adjs.append(mol_am)\n",
    "    mol_conns.append(mol_conn)\n",
    "    mol_edge_adjs.append(mol_edgeAdj)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965c3aa-e662-4089-99f1-2453733ac57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_vertices = tf.convert_to_tensor(mol_vertices)\n",
    "mol_edges = tf.convert_to_tensor(mol_edges)\n",
    "mol_unis = tf.convert_to_tensor(mol_unis)\n",
    "mol_adjs = tf.convert_to_tensor(mol_adjs)\n",
    "mol_conns = tf.convert_to_tensor(mol_conns)\n",
    "mol_edge_adjs = tf.convert_to_tensor(mol_edge_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282c1037-8644-4d21-9f30-1d5642c0f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_gene_cell_to_de = {}\n",
    "for index, example in de_data_train.iterrows():\n",
    "    mol_id = mol_to_id[example[\"sm_name\"]]\n",
    "    cell_type = example[\"cell_type_int\"]\n",
    "    for gene_name in gene_names:\n",
    "        gene_id = gene_symbol_to_id[gene_name]\n",
    "        mol_gene_cell_to_de[(mol_id, gene_id, cell_type)] = example[gene_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97f51a-22ba-4785-934f-c2fdfb42f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in testing_combinations.keys():\n",
    "    print(cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2578a90-acda-498b-bffc-73560a48fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = set({})\n",
    "\n",
    "for cell_type in training_combinations.keys():\n",
    "    for mol_name in training_combinations[cell_type]:\n",
    "            for gene_name in gene_names:\n",
    "                mol_id = mol_to_id[mol_name]\n",
    "                gene_id = gene_symbol_to_id[gene_name]\n",
    "                cell_id = cellNameToInt[cell_type]\n",
    "                \n",
    "                training_pairs.add((mol_id, gene_id, cell_id))\n",
    "\n",
    "testing_pairs = set({})\n",
    "\n",
    "for cell_type in testing_combinations.keys():\n",
    "    for mol_name in testing_combinations[cell_type]:\n",
    "            for gene_name in gene_names:\n",
    "                mol_id = mol_to_id[mol_name]\n",
    "                gene_id = gene_symbol_to_id[gene_name]\n",
    "                cell_id = cellNameToInt[cell_type]\n",
    "                \n",
    "                testing_pairs.add((mol_id, gene_id, cell_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0ca5d-2d7b-44f8-afa1-bbb52a0fb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afbb1a-bcca-47ce-9abb-a87f51174ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mol_ids = []\n",
    "training_gene_ids = []\n",
    "training_cell_types = []\n",
    "training_de_vals = []\n",
    "\n",
    "training_pairs = list(training_pairs)\n",
    "\n",
    "for i in permutation(len(training_pairs)):\n",
    "    mol_id, gene_id, cell_id = training_pairs[i]\n",
    "    de = mol_gene_cell_to_de[(mol_id, gene_id, cell_id)]\n",
    "    \n",
    "    training_mol_ids.append(mol_id)\n",
    "    training_gene_ids.append(gene_id)\n",
    "    training_cell_types.append(cell_id)\n",
    "    training_de_vals.append(de)\n",
    "\n",
    "testing_mol_ids = []\n",
    "testing_gene_ids = []\n",
    "testing_cell_types = []\n",
    "testing_de_vals = []\n",
    "\n",
    "testing_pairs = list(testing_pairs)\n",
    "\n",
    "for i in permutation(len(testing_pairs)):\n",
    "    mol_id, gene_id, cell_id = testing_pairs[i]\n",
    "    de = mol_gene_cell_to_de[(mol_id, gene_id, cell_id)]\n",
    "    \n",
    "    testing_mol_ids.append(mol_id)\n",
    "    testing_gene_ids.append(gene_id)\n",
    "    testing_cell_types.append(cell_id)\n",
    "    testing_de_vals.append(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a895897-d558-46e9-bbb7-63530a0bf239",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mol_ids = tf.convert_to_tensor(training_mol_ids)\n",
    "training_gene_ids = tf.convert_to_tensor(training_gene_ids)\n",
    "training_cell_types = tf.convert_to_tensor(training_cell_types)\n",
    "training_de_vals = tf.convert_to_tensor(training_de_vals)\n",
    "\n",
    "testing_mol_ids = tf.convert_to_tensor(testing_mol_ids)\n",
    "testing_gene_ids = tf.convert_to_tensor(testing_gene_ids)\n",
    "testing_cell_types = tf.convert_to_tensor(testing_cell_types)\n",
    "testing_de_vals = tf.convert_to_tensor(testing_de_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d929725-e717-4f5e-b060-6daf9a3d1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_sequences(in_mol_ids, in_gene_ids, in_cell_types, in_de_vals):\n",
    "    current_gene_sequences = tf.gather(gene_sequences, in_gene_ids)\n",
    "    return in_mol_ids, in_gene_ids, current_gene_sequences, in_cell_types, in_de_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b649d2-9be0-4eca-8252-86009f28222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mol_graphs(in_mol_ids, in_gene_ids, in_gene_seqs, in_cell_types, in_de_vals):\n",
    "    current_mol_vertices = tf.gather(mol_vertices, in_mol_ids)\n",
    "    current_mol_edges = tf.gather(mol_edges, in_mol_ids)\n",
    "    current_mol_unis = tf.gather(mol_unis, in_mol_ids)\n",
    "    current_mol_adjs = tf.gather(mol_adjs, in_mol_ids)\n",
    "    current_mol_conns = tf.gather(mol_conns, in_mol_ids)\n",
    "    current_mol_edge_adjs = tf.gather(mol_edge_adjs, in_mol_ids)\n",
    "    \n",
    "    return current_mol_vertices, current_mol_edges, current_mol_unis, current_mol_adjs, current_mol_conns, current_mol_edge_adjs, in_gene_ids, in_gene_seqs, in_cell_types, in_de_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fae2c0-71ba-40ef-ad60-72f3715478e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_tensors(in_mol_vertices, \n",
    "                 in_mol_edges, \n",
    "                 in_mol_unis, \n",
    "                 in_mol_adjs, \n",
    "                 in_mol_conns, \n",
    "                 in_mol_edge_adjs,\n",
    "                 in_gene_ids,\n",
    "                 in_gene_seqs, \n",
    "                 in_cell_types, \n",
    "                 in_de_vals):\n",
    "    return {\n",
    "        \"mol_ver\": in_mol_vertices,\n",
    "        \"mol_edj\": in_mol_edges,\n",
    "        \"mol_uni\": in_mol_unis,\n",
    "        \"mol_am\": in_mol_adjs,\n",
    "        \"mol_conn\": in_mol_conns,\n",
    "        \"mol_edgeAdj\": in_mol_edge_adjs,\n",
    "        \"gene_id\": in_gene_ids,\n",
    "        \"dna_seq\": in_gene_seqs,\n",
    "        \"cell_type\": in_cell_types\n",
    "    }, in_de_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac4c92-7727-4a4a-b737-864c15a420d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphLayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db276580-e6d0-45a0-8db9-0c422f247aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    vertices = Input(shape=((MAX_NODES, EMBEDDING_DIM,)), name=\"mol_ver\")\n",
    "    edges = Input(shape=((MAX_EDGES, EMBEDDING_DIM,)), name=\"mol_edj\")\n",
    "    universal = Input(shape=((EMBEDDING_DIM,)), name=\"mol_uni\")\n",
    "    adj = Input(shape=((MAX_NODES, MAX_NODES,)), name=\"mol_am\")\n",
    "    conEd = Input(shape=((MAX_NODES, MAX_EDGES,)), name=\"mol_conn\")\n",
    "    edgeAdj = Input(shape=((MAX_EDGES, MAX_EDGES,)), name=\"mol_edgeAdj\")\n",
    "    dna_sequence = Input(shape=((40000,)), name=\"dna_seq\")\n",
    "    geneID = Input(shape=((1,)), name=\"gene_id\")\n",
    "    cellType = Input(shape=((1,)), name=\"cell_type\")\n",
    "    \n",
    "    x = [vertices, edges, universal, adj, conEd, edgeAdj]\n",
    "\n",
    "    for i in range(params[\"graph_layers\"]):\n",
    "        for k in range(params[\"pool_steps\"]):\n",
    "            x = PoolStep(params[f\"step_{k}_pve\"],\n",
    "                        params[f\"step_{k}_pee\"],\n",
    "                        params[f\"step_{k}_pue\"],\n",
    "                        params[f\"step_{k}_pvv\"],\n",
    "                        params[f\"step_{k}_pev\"],\n",
    "                        params[f\"step_{k}_puv\"],\n",
    "                        params[f\"step_{k}_pvu\"],\n",
    "                        params[f\"step_{k}_peu\"])(x)\n",
    "        x = GraphUpdate(params[\"embedding_dim\"], params[\"embedding_dim\"], params[\"embedding_dim\"], params[\"update_function_depth\"], activation=\"relu\", dropout=params[\"dropout\"])(x)\n",
    "\n",
    "    x = PoolStep(p_ve=False,\n",
    "                p_ee=False,\n",
    "                p_ue=False,\n",
    "                p_vv=False,\n",
    "                p_ev=False,\n",
    "                p_uv=False,\n",
    "                p_vu=True,\n",
    "                p_eu=True)(x)\n",
    "    \n",
    "    u = x[2]\n",
    "\n",
    "    final_tensors = [u, cellType]\n",
    "    \n",
    "    if params[\"use_gene_sequence\"]:\n",
    "        dna_seq = Dense(64)(dna_sequence)\n",
    "        dna_seq = tf.keras.layers.LeakyReLU()(dna_seq)\n",
    "        dna_seq = tf.keras.layers.BatchNormalization()(dna_seq)\n",
    "        \n",
    "        dna_seq = Dense(32)(dna_seq)\n",
    "        dna_seq = tf.keras.layers.LeakyReLU()(dna_seq)\n",
    "        dna_seq = tf.keras.layers.BatchNormalization()(dna_seq)\n",
    "        \n",
    "        dna_seq = Dense(16)(dna_seq)\n",
    "        dna_seq = tf.keras.layers.LeakyReLU()(dna_seq)\n",
    "        dna_seq = tf.keras.layers.BatchNormalization()(dna_seq)\n",
    "        \n",
    "        final_tensors.append(dna_seq)\n",
    "        \n",
    "    if params[\"use_gene_id\"]:\n",
    "        final_tensors.append(geneID)\n",
    "\n",
    "    u = Concatenate()(final_tensors)\n",
    "    \n",
    "    for i in range(params[\"num_final_layers\"]):\n",
    "        u = Dense(16)(u)\n",
    "        u = tf.keras.layers.LeakyReLU()(u)\n",
    "        u = tf.keras.layers.BatchNormalization()(u)\n",
    "\n",
    "    u = Dense(1)(u)\n",
    "    \n",
    "    return Model(inputs=[vertices, edges, universal, adj, conEd, edgeAdj, geneID, cellType, dna_sequence], outputs=u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716df7a-3b98-44dc-9f33-2c4538a8ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parameter_set():\n",
    "    params = {}\n",
    "\n",
    "    params[\"graph_layers\"] = random.randint(1, 5)\n",
    "    params[\"pool_steps\"] = random.randint(3, 5)\n",
    "\n",
    "    params[\"update_function_depth\"] = random.randint(1, 5)\n",
    "\n",
    "    for k in range(params[\"pool_steps\"]):\n",
    "        params[f\"step_{k}_pve\"] = random.choice([True, False])\n",
    "        params[f\"step_{k}_pee\"] = random.choice([True, False])\n",
    "        params[f\"step_{k}_pue\"] = random.choice([True, False])\n",
    "        params[f\"step_{k}_pvv\"] = random.choice([True, False])\n",
    "        params[f\"step_{k}_pev\"] = random.choice([True, False])\n",
    "        params[f\"step_{k}_puv\"] = random.choice([True, False])\n",
    "        params[f\"step_{k}_pvu\"] = random.choice([True, False])\n",
    "        params[f\"step_{k}_peu\"] = random.choice([True, False])\n",
    "\n",
    "    #params[\"embedding_dim\"] = random.choice([10, 50, 60, 70, 80, 90, 100])\n",
    "    params[\"embedding_dim\"] = 64\n",
    "    params[\"num_final_layers\"] = random.randint(1, 5)\n",
    "\n",
    "    params[\"optimizer\"] = random.choice([\"Adam\", \"SGD\"])\n",
    "    params[\"optimizer\"] = \"Adam\"\n",
    "    \n",
    "    if params[\"optimizer\"] == \"RMSProp\":\n",
    "        #params[\"learning_rate\"] = random.uniform(0.0001, 0.1)\n",
    "        params[\"learning_rate\"] = 0.001\n",
    "\n",
    "    if params[\"optimizer\"] == \"Adam\":\n",
    "        #params[\"learning_rate\"] = random.uniform(0.00001, 0.1)\n",
    "        params[\"learning_rate\"] = random.choice([0.0001, 0.00001])\n",
    "\n",
    "    if params[\"optimizer\"] == \"SGD\":\n",
    "        #params[\"learning_rate\"] = random.uniform(0.001, 0.1)\n",
    "        params[\"learning_rate\"] = random.choice([0.01, 0.001])\n",
    "\n",
    "    params[\"batch_size\"] = 512\n",
    "    params[\"dropout\"] = random.choice([True, False])\n",
    "    params[\"dropout\"] = True\n",
    "    \n",
    "    #params[\"use_gene_sequence\"] = random.choice([True, True, False])\n",
    "    #params[\"use_gene_id\"] = random.choice([True, True, False])\n",
    "    params[\"use_gene_sequence\"] = random.choice([True, False])\n",
    "    params[\"use_gene_id\"] = True\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772cb9a2-af63-46c3-b84b-4bf33168e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = generate_parameter_set()\n",
    "\n",
    "model = build_model(params)\n",
    "\n",
    "if params[\"optimizer\"] == \"RMSProp\":\n",
    "    optimizer=tf.keras.optimizers.RMSprop(params[\"learning_rate\"], clipnorm=1)\n",
    "\n",
    "if params[\"optimizer\"] == \"Adam\":\n",
    "    optimizer=tf.keras.optimizers.Adam(params[\"learning_rate\"], clipnorm=1)\n",
    "\n",
    "if params[\"optimizer\"] == \"SGD\":\n",
    "    optimizer=tf.keras.optimizers.SGD(params[\"learning_rate\"], clipnorm=1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969b7bc-1a2c-418e-906d-a202e458febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((training_mol_ids, \n",
    "                                                       training_gene_ids, \n",
    "                                                       training_cell_types, \n",
    "                                                       training_de_vals))\n",
    "training_dataset = training_dataset.batch(512)\n",
    "training_dataset = training_dataset.map(get_gene_sequences, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "training_dataset = training_dataset.map(get_mol_graphs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "training_dataset = training_dataset.map(name_tensors, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "training_dataset = training_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((testing_mol_ids, \n",
    "                                                       testing_gene_ids, \n",
    "                                                       testing_cell_types, \n",
    "                                                       testing_de_vals))\n",
    "testing_dataset = testing_dataset.batch(512)\n",
    "testing_dataset = testing_dataset.map(get_gene_sequences, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "testing_dataset = testing_dataset.map(get_mol_graphs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "testing_dataset = testing_dataset.map(name_tensors, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "testing_dataset = testing_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400884a-9955-42ee-b1d7-290501933a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.layer_utils import count_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b8a40-0486-46a4-9a55-821ef809579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "nan_stopper = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(training_dataset, validation_data=testing_dataset, epochs=100, callbacks=[stopper, nan_stopper])\n",
    "train_time = time.time()-start\n",
    "\n",
    "if \"val_loss\" not in history.history:\n",
    "    log_line = {\"time\": time.time(),\n",
    "            \"config\": params, \n",
    "            \"history\": history.history,\n",
    "            \"nan_fail\": True}\n",
    "    with open(\"logfile_compute.jsonl\", \"a\") as logfile:\n",
    "        logfile.write(json.dumps(log_line)+\"\\n\")\n",
    "\n",
    "else:\n",
    "    lowest_loss = min(history.history[\"val_loss\"])\n",
    "    train_steps = history.history[\"val_loss\"].index(lowest_loss)\n",
    "    \n",
    "    trainable_params = sum(count_params(layer) for layer in model.trainable_weights)\n",
    "    non_trainable_params = sum(count_params(layer) for layer in model.non_trainable_weights)\n",
    "    \n",
    "    log_line = {\"time\": time.time(),\n",
    "                \"config\": params, \n",
    "                \"history\": history.history, \n",
    "                \"lowest_val_loss\": lowest_loss, \n",
    "                \"train_steps\": train_steps, \n",
    "                \"train_time\": train_time,\n",
    "                \"trainable_params\": trainable_params,\n",
    "                \"non_trainable_params\": non_trainable_params}\n",
    "    \n",
    "    with open(\"logfile_compute.jsonl\", \"a\") as logfile:\n",
    "        logfile.write(json.dumps(log_line)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9022890-5935-4615-a59d-3d3ebaf50e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
